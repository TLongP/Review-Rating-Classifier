{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_tfrecord(tfrecord):\n",
    "    \"\"\" preprocess for reading\n",
    "    \"\"\"\n",
    "    feature_descriptions = {\n",
    "        \"review\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"sentiment\": tf.io.FixedLenFeature([], tf.int64, default_value=0)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    return example[\"review\"], example[\"sentiment\"]\n",
    "\n",
    "def load_tfrecord(filepaths, n_read_threads=5, shuffle_buffer_size=10000,\n",
    "                n_parse_threads=5, batch_size=32, cache=True):\n",
    "    \"\"\" first convert the filepath into tfdataset, then shuffle the files\n",
    "        then reading the data from files\n",
    "        by using prefetch in -> make faster (prepare the next data even the current data not finishes)\"\"\"\n",
    "    dataset = tf.data.TFRecordDataset(filepaths,\n",
    "                                      num_parallel_reads=n_read_threads)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess_for_tfrecord, num_parallel_calls=n_parse_threads)\n",
    "    return dataset.batch(batch_size).prefetch(1)      \n",
    "\n",
    "def list_files_in_path(pathfile):\n",
    "    files = []\n",
    "    for file in os.listdir(pathfile):\n",
    "        files.append(os.path.join(pathfile,file))\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = load_tfrecord(list_files_in_path(\"datasets\\\\tfrecords\\\\train\"))\n",
    "valid_set = load_tfrecord(list_files_in_path(\"datasets\\\\tfrecords\\\\validation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"you can change the following parameters\n",
    "    One can also use the Keras Tuner to tune the embedding dim\"\"\"\n",
    "num_of_words = 10000\n",
    "max_sentence_len = 200\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorize_dict = {\n",
    "    \"max_tokens\": num_of_words,\n",
    "    \"output_mode\": \"int\",\n",
    "    \"output_sequence_length\":max_sentence_len\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(**text_vectorize_dict)\n",
    "vectorize_layer._name=\"Text_Vectorization_Layer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(train_set.map(lambda x,y: x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USE KERAS TUNER ###\n",
    "We find the optimal parameters in our set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tuner(hp):\n",
    "    model = Sequential()\n",
    "    model.add(vectorize_layer)\n",
    "    model.add(layers.Embedding(input_dim=num_of_words,output_dim=embedding_dim,\n",
    "                                input_length=max_sentence_len,name=\"Embedding_layer\"))\n",
    "    conv1_filters = hp.Choice(\"conv1_filters\",values=[16,32,64,128])\n",
    "    conv1_kernels = hp.Choice(\"conv1_kernels\",values=[3,5,7,9,11])\n",
    "    model.add(layers.Conv1D(filters=conv1_filters,kernel_size=conv1_kernels,\n",
    "                            activation='selu',kernel_initializer='lecun_normal'))\n",
    "    model.add(layers.GlobalAveragePooling1D())\n",
    "    dense_1_units = hp.Int('dense_1_units', min_value=6, max_value=10, step=1)\n",
    "    model.add(layers.Dense(units=dense_1_units,activation='selu',kernel_initializer='lecun_normal'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(loss=\"BinaryCrossentropy\",metrics=['accuracy'],optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_tuner,objective='val_accuracy',\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='movie_reviews')\n",
    "early_stopping = callbacks.EarlyStopping(monitor=\"val_loss\",patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_set,epochs=50,validation_data=valid_set,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "the hyperparameter search is complete. The optimal numbers of parameters are\n",
    "conv1_filters: {best_hps.get(\"conv1_filters\")}\n",
    "conv1_kernels: {best_hps.get(\"conv1_kernels\")}\n",
    "dense_1_units: {best_hps.get(\"dense_1_units\")}\n",
    "learning_rate: {best_hps.get(\"learning_rate\")}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the best parameter for the search are:\n",
    "conv1_filters: 64\n",
    "conv1_kernels: 3\n",
    "dense_1_units: 9\n",
    "learning_rate: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf_board_dir = \"logs/train_tf_board/\"+datetime.now().strftime(\"%Y%m%d--%H%M%S\")\n",
    "check_point_dir = \"logs/check_point\"\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=tf_board_dir)\n",
    "early_stopping = callbacks.EarlyStopping(monitor=\"val_loss\",patience=10)\n",
    "check_point = callbacks.ModelCheckpoint(filepath=check_point_dir,\n",
    "                                        monitor=\"val_loss\",\n",
    "                                        save_best_only=True,\n",
    "                                        save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    return lr*0.5**(epoch//10)\n",
    "learning_rate_scheduler =callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"If you use the model which we find by using keras\n",
    "     tuner then you do not need to do run this cell\"\"\"\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.models.Sequential([\n",
    "    vectorize_layer,\n",
    "    layers.Embedding(input_dim=num_of_words,output_dim=16,input_length=max_sentence_len),\n",
    "    tf.keras.layers.Conv1D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(9, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"BinaryCrossentropy\",metrics=['accuracy'],optimizer=Adam(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 19s 13ms/step - loss: 0.3585 - accuracy: 0.8429 - val_loss: 0.2894 - val_accuracy: 0.8778 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.2311 - accuracy: 0.9083 - val_loss: 0.2967 - val_accuracy: 0.8742 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.1835 - accuracy: 0.9294 - val_loss: 0.3262 - val_accuracy: 0.8710 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 0.1392 - accuracy: 0.9492 - val_loss: 0.4241 - val_accuracy: 0.8610 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.1022 - accuracy: 0.9646 - val_loss: 0.4610 - val_accuracy: 0.8590 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.0758 - accuracy: 0.9735 - val_loss: 0.5268 - val_accuracy: 0.8448 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.0572 - accuracy: 0.9794 - val_loss: 0.7485 - val_accuracy: 0.8460 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.0432 - accuracy: 0.9841 - val_loss: 0.7882 - val_accuracy: 0.8508 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.0396 - accuracy: 0.9851 - val_loss: 0.9636 - val_accuracy: 0.8566 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.0309 - accuracy: 0.9882 - val_loss: 1.0427 - val_accuracy: 0.8542 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 0.0147 - accuracy: 0.9939 - val_loss: 1.2026 - val_accuracy: 0.8532 - lr: 0.0050\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set,\n",
    "            epochs=100,\n",
    "            batch_size=32,\n",
    "            validation_data=valid_set,\n",
    "            callbacks=[early_stopping,\n",
    "                    check_point,\n",
    "                    learning_rate_scheduler,\n",
    "                    tensorboard_callback]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2061a2f8820>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(check_point_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Training Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20647627b20>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "plt.plot(np.arange(len(train_acc)),train_acc,\"r\",label=\"training accuracy\")\n",
    "plt.plot(np.arange(len(val_acc)),val_acc,\"b\",label=\"validation accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anlayse**\n",
    "\n",
    "It looks like our model has overfitten the training data.\n",
    "What can we do? So first we can collect more data. \n",
    "But we can also add a dropout layer.\n",
    "\n",
    "If this wont work out we cann try GRU or LSTM layer, since the training for LSTM take longer I will not use it here.\n",
    "\n",
    "But now let look at the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = load_tfrecord(list_files_in_path(\"datasets\\\\tfrecords\\\\test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_accuracy(test_set):\n",
    "    accuracy = tf.keras.metrics.Accuracy()\n",
    "    for x,y in test_set.map(lambda x,y: (x,y)):\n",
    "        accuracy.update_state(y,model.predict(x)>0.5)\n",
    "    return accuracy.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8752>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_accuracy(test_set=test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get 87.5% accuracy on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Text_Vectorization_Layer_input with unsupported characters which will be renamed to text_vectorization_layer_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_mdoel/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_mdoel/model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"saved_model/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c857caae20f38d1b296763322fac57da2e4d73991c1f9c93d349f69327511a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('deep_learning_with_python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
